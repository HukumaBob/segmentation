{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n",
      "UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1b45c1cc5c41efb46327b5058658ee",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "BBoxWidget(colors=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#b…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import base64\n",
    "\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CHECKPOINT = \"segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "CONFIG = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "sam2_model = build_sam2(CONFIG, CHECKPOINT, device=DEVICE, apply_postprocessing=False)    \n",
    "\n",
    "# Автоматическая генерация маски\n",
    "\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2_model)\n",
    "\n",
    "IMAGE_PATH = \"example.png\"\n",
    "\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "sam2_result = mask_generator.generate(image_rgb)\n",
    "\n",
    "# # Визуализация результатов\n",
    "\n",
    "# mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "# detections = sv.Detections.from_sam(sam_result=sam2_result)\n",
    "\n",
    "# annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
    "\n",
    "# sv.plot_images_grid(\n",
    "#     images=[image_bgr, annotated_image],\n",
    "#     grid_size=(1, 2),\n",
    "#     titles=['source image', 'segmented image']\n",
    "# )\n",
    "# masks = [\n",
    "#     mask['segmentation']\n",
    "#     for mask\n",
    "#     in sorted(sam2_result, key=lambda x: x['area'], reverse=True)\n",
    "# ]\n",
    "\n",
    "# sv.plot_images_grid(\n",
    "#     images=masks[:16],\n",
    "#     grid_size=(4, 4),\n",
    "#     size=(12, 12)\n",
    "# )\n",
    "# # Расширенные возможности автоматической генерации масок\n",
    "\n",
    "# mask_generator_2 = SAM2AutomaticMaskGenerator(\n",
    "#     model=sam2_model,\n",
    "#     points_per_side=64,\n",
    "#     points_per_batch=128,\n",
    "#     pred_iou_thresh=0.7,\n",
    "#     stability_score_thresh=0.92,\n",
    "#     stability_score_offset=0.7,\n",
    "#     crop_n_layers=1,\n",
    "#     box_nms_thresh=0.7,\n",
    "# )\n",
    "# sam2_result_2 = mask_generator_2.generate(image_rgb)\n",
    "# mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "# detections = sv.Detections.from_sam(sam_result=sam2_result_2)\n",
    "\n",
    "# annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
    "\n",
    "# sv.plot_images_grid(\n",
    "#     images=[image_bgr, annotated_image],\n",
    "#     grid_size=(1, 2),\n",
    "#     titles=['source image', 'segmented image']\n",
    "# )\n",
    "\n",
    "# Подсказки с полями\n",
    "\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Интерактивное окно подсказки\n",
    "def encode_image(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    encoded = str(base64.b64encode(image_bytes), 'utf-8')\n",
    "    return \"data:image/jpg;base64,\"+encoded\n",
    "\n",
    "widget = BBoxWidget()\n",
    "widget.image = encode_image(IMAGE_PATH)\n",
    "widget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
